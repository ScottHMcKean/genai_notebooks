{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79f46683-790d-41a1-ba93-65f4fa42e24c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Les Misér-AI-bles: Batching Through the Barricades\n",
    "## Spark Profiling\n",
    "\n",
    "This notebook takes our previously ingested table and uses Spark UDFs to run our prompt against three OpenAI endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efa9edf7-291e-4533-8fef-6fd156b3debf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-agents --quiet\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e478c9e-7d0f-4b0a-8234-4e7e24eb21e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d94e9221-5c46-4239-b954-3e261e0a4aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "workspace_client = WorkspaceClient()\n",
    "workspace_url = workspace_client.config.host\n",
    "\n",
    "# Check if running in Databricks\n",
    "import os\n",
    "\n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "    token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "else:\n",
    "    token = workspace_client.config.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "572924a3-ec07-4a48-8986-243fa459cd5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "import time\n",
    "import json\n",
    "\n",
    "def extract_data_from_passage(header2, header3, page_content):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    client = OpenAI(\n",
    "        api_key=token,\n",
    "        base_url=f\"{workspace_url}/serving-endpoints\",\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='azure-o1',\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "             Take this passage from Les Miserables and do structured data extraction in JSON. I want you to provide the title of the chapter, a list of characters, a synopsis of the chapter, and the overall sentiment of the chapter - positive, neutral, or negative. Do not make up anything if the passage isn't part of the novel. Also include 'experiment: o1-udf'\n",
    "\n",
    "             Output Format:\n",
    "                title: \n",
    "                characters: []\n",
    "                synopsis:\n",
    "                sentiment:\n",
    "                experiment:\n",
    "\n",
    "             {header2}\n",
    "             {header3}\n",
    "             {page_content}\n",
    "             \"\"\"}\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    return response.choices[0].message.content.replace(\"json\\n\",\"\").replace(\"\",\"\") + f\"time: {elapsed_time:.2f}\"\n",
    "\n",
    "extract_data_udf = udf(extract_data_from_passage, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d723bff-f26c-4ff4-ba02-28b418b70238",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = mlflow.dspy.load_model(...\"champion\")\n",
    "UDF --> model.predict()\n",
    "model.to_spark_udf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "146cafc3-f062-4462-bca2-0ced696f6704",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "from openai import OpenAI\n",
    "\n",
    "# EXAMPLE: using OpenAI GPT-3.5/4, but any OpenAI-compatible model works.\n",
    "# For other LLMs (e.g. via HuggingFace), use a compatible interface (see DsPy docs).\n",
    "\n",
    "llm = OpenAI(api_key=\"your-api-key\", model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Register the LLM in DsPy (this makes it the backend for dspy.Predict etc.)\n",
    "dspy.settings.configure(llm=llm)\n",
    "\n",
    "# Rest of your DsPy code:\n",
    "class CharacterSignature(dspy.Signature):\n",
    "    passage: str = dspy.InputField(desc=\"Text from Les Misérables\")\n",
    "    characters: list[str] = dspy.OutputField(desc=\"List of named characters mentioned in the passage\")\n",
    "\n",
    "character_extractor = dspy.Predict(CharacterSignature)\n",
    "result = character_extractor(passage=\"Jean Valjean met Fantine and Javert at the inn.\")\n",
    "print(result.characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dddfe150-6813-4a83-9a24-4e7e84854277",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "import time\n",
    "import json\n",
    "\n",
    "def extract_data_from_passage(header2, header3, page_content):\n",
    "    model = mlflow.dspy.load_model(...\"champion\")\n",
    "    return model.predict()\n",
    "\n",
    "extract_data_udf = udf(extract_data_from_passage, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fef9d78-07a7-4243-b292-7990d9ff0119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output = les_mis_df.repartition(24).withColumn(\n",
    "    \"extracted_data\", \n",
    "    extract_data_udf(les_mis_df.header_2, les_mis_df.header_3, les_mis_df.page_content)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49b2d536-2711-461c-84a3-92ea77e7ce94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d56e74d4-cb12-43b1-bd5b-eac35ea611c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output.write.mode('overwrite').saveAsTable('shm.default.`azure-o1_profiling`')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "les_miserables_spark",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
