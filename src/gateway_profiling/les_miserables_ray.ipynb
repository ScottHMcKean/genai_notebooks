{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efa9edf7-291e-4533-8fef-6fd156b3debf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install bs4 databricks-agents langchain-text-splitters --quiet\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e478c9e-7d0f-4b0a-8234-4e7e24eb21e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A Chunky View on Les Miserables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4be51c3-7b67-472b-ad28-86b0a3bae54d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://www.gutenberg.org/cache/epub/135/pg135-images.html')\n",
    "miserables_text = response.text\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(miserables_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "804eabc7-698c-424b-b819-686aea72b84e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This gives us 369 chunks, 365 of which are chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7a47ff7-e82b-4e9e-82d9-bef9257ac942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "valid_chunks = [x for x in html_header_splits if len(x.page_content) > 1000][1:]\n",
    "valid_chunk_lengths = [len(x.page_content) for x in valid_chunks]\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.hist(valid_chunk_lengths, bins=20, edgecolor='black')\n",
    "plt.title('Histogram of Valid Chunk Lengths')\n",
    "plt.xlabel('Length of Valid Chunks')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3913962-d767-4917-83c0-90f42c85ae13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_passage(passage):\n",
    "  return {\n",
    "    \"header_2\": passage.metadata.get('Header 2',\"\"),\n",
    "    \"header_3\": passage.metadata.get('Header 3',\"\"),\n",
    "    \"page_content\": passage.page_content\n",
    "}\n",
    "  \n",
    "extracted_passages = [extract_passage(x) for x in valid_chunks]\n",
    "les_mis_df = pd.DataFrame(extracted_passages)\n",
    "les_mis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d94e9221-5c46-4239-b954-3e261e0a4aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "workspace_client = WorkspaceClient()\n",
    "workspace_url = workspace_client.config.host\n",
    "\n",
    "# Check if running in Databricks\n",
    "import os\n",
    "\n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "    token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "else:\n",
    "    token = workspace_client.config.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec82f97-079c-46fd-a77e-2e545b32e1ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "passage = valid_chunks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7406468-fa18-4b5d-8770-23f69d2e9412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=token,\n",
    "    base_url=f\"{workspace_url}/serving-endpoints\",\n",
    ")\n",
    "\n",
    "# Query AI Gateway\n",
    "response = client.chat.completions.create(\n",
    "    model='azure-gpt-4o-mini',\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "         Take this passage from Les Miserables and do structured data extraction in JSON. I want you to provide the title of the chapter, a list of characters, a synopsis of the chapter, and the overall sentiment of the chapter - positive, neutral, or negative. Do not make up anything if the passage isn't part of the novel.\n",
    "         \n",
    "         {passage.metadata['Header 2']}\n",
    "         {passage.metadata['Header 3']}\n",
    "         {passage.page_content}\n",
    "         \"\"\"}\n",
    "    ],\n",
    "    extra_headers={\"client_request_id\":'test'}\n",
    ")\n",
    "\n",
    "# Extract json response\n",
    "response.choices[0].message.content.replace(\"json\\n\",\"\").replace(\"```\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97154279-520a-44a0-9d4e-ad57f2d6e43b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Initialize Ray Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc1345b5-3f3d-42f1-b661-b9997b0ac11f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from ray.util.spark import setup_ray_cluster\n",
    "import ray\n",
    "\n",
    "setup_ray_cluster(\n",
    "  min_worker_nodes=3,\n",
    "  max_worker_nodes=3,\n",
    ")\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1b7ffb6-ad64-41c5-8552-02815006ab86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_list = les_mis_df.to_dict(orient='records')\n",
    "data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad26f56-498e-4154-b0f9-f2c15a3f5d23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@ray.remote(num_cpus=1)\n",
    "def extract_data_from_passage_ray(data_dict):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "    \n",
    "        client = OpenAI(\n",
    "            api_key=token,\n",
    "            base_url=f\"{workspace_url}/serving-endpoints\",\n",
    "        )\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model='azure-gpt4o',\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                Take this passage from Les Miserables and do structured data extraction in JSON. I want you to provide the title of the chapter, a list of characters, a synopsis of the chapter, and the overall sentiment of the chapter - positive, neutral, or negative. Do not make up anything if the passage isn't part of the novel. Also include 'experiment: gpt4o-ray'\n",
    "\n",
    "                Output Format:\n",
    "                    title: \n",
    "                    characters: []\n",
    "                    synopsis:\n",
    "                    sentiment:\n",
    "                    experiment:\n",
    "\n",
    "                {data_dict['header_2']}\n",
    "                {data_dict['header_3']}\n",
    "                {data_dict['page_content']}\n",
    "                \"\"\"}\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        data_dict['extracted_data'] = response.choices[0].message.content.replace(\"json\\n\",\"\").replace(\"\",\"\") + f\"time: {elapsed_time:.2f}\"\n",
    "    except: \n",
    "        data_dict['extracted_data'] = \"ERROR\"\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a554f649-e0b5-4861-9a2e-150f8e210d26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "futures = [extract_data_from_passage_ray.remote(data) for data in data_list] \n",
    "results = ray.get(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09a2e66f-9e03-47b7-a943-bdf4843515e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd_df = pd.DataFrame(results)\n",
    "pd_df.iloc[3].extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d56e74d4-cb12-43b1-bd5b-eac35ea611c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save as files since we've hijacked our spark clusters\n",
    "pd_df.to_csv(\"/Volumes/shm/default/llm_profiling/les_mis_df-azure-o1-ray.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "les_miserables_ray",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
