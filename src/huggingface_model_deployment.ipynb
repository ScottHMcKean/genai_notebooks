{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a65ac522-b588-4b8b-8115-b25dd21f90b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Huggingface PT Models\n",
    "This notebook registers hugging face models to Unity Catalog and deploys it via model serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f4e44df-54ec-4133-8506-85cb6627f9ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Model from HuggingFace\n",
    "Our serving journey starts with how we load the model from huggingface. We leverage the 'Auto' library from the HuggingFace transformers package because of its compatibility with MLFLow and Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "246944d9-34d5-48cc-9fcc-ea5f2bf2c9dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load model from Hugging Face\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'braindao/Qwen2.5-14B',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('braindao/Qwen2.5-14B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "368f6704-635a-47c8-bc18-d6748e9819ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log model to MLflow and register in Unity Catalog\n",
    "import mlflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Define input example\n",
    "    input_example = {\"prompt\": \"What is machine learning?\"}\n",
    "    \n",
    "    # Log model with Unity Catalog format\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model={\"model\": model, \"tokenizer\": tokenizer},\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"prod.ml_team.llama7b_chat\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1619bcab-55a1-44ff-ad70-5fdf04b23bf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Deploy to Model Serving using MLflow Deployments SDK\n",
    "from mlflow.deployments import get_deploy_client\n",
    "client = get_deploy_client(\"databricks\")\n",
    "\n",
    "endpoint_name = \"llama7b-chat-endpoint\"\n",
    "client.create_endpoint(\n",
    "    name=endpoint_name,\n",
    "    config={\n",
    "        \"served_entities\": [{\n",
    "            \"entity_name\": \"prod.ml_team.llama7b_chat\",\n",
    "            \"entity_version\": \"1\",\n",
    "            \"workload_size\": \"Medium\",\n",
    "            \"scale_to_zero_enabled\": False\n",
    "        }]\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2275659824956874,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "huggingface_model_deployment",
   "widgets": {
    "model_id": {
     "currentValue": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
     "nuid": "ee14d6e3-995d-4f2e-b12f-779bb5e0d267",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "label": "Name of Huggingface Model",
      "name": "model_id",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "label": "Name of Huggingface Model",
      "name": "model_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
