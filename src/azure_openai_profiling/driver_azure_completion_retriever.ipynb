{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0a5918-8371-4c97-af94-341633367175",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow==2.18.0 openai==1.61.0 databricks-agents httpx==0.27.2\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a1ac11d-400d-439f-b211-eaf065d1c5c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Doing this with MLFLow=2.20.1 gives the following error `{\"error_code\": \"BAD_REQUEST\", \"message\": \"Expected list, but got ndarray\"}`. I had to pin at MLFlow = 2.18.0 (2.16 doesn't work nor does 2.19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41c0fd22-76c1-41bc-95c6-88df3e5225c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import ModelConfig\n",
    "config = ModelConfig(development_config='config.yaml')\n",
    "\n",
    "import os\n",
    "os.environ[\"API_SECRET_KEY\"] = dbutils.secrets.get('shm', config.get(\"api_secret_key\"))\n",
    "os.environ[\"SEARCH_SECRET_KEY\"] = dbutils.secrets.get('shm', config.get(\"search_secret_key\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c66eaa-2738-47ed-8008-5322ecbf1531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load the Test Approaches and Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75ac0d21-51ca-46f5-86be-30b1c0b444b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyfunc_azure_completion_retriever import AzureCompletionRetriever\n",
    "\n",
    "approach = {\n",
    "    'name': 'azurecompletionretriever',\n",
    "    'file': 'pyfunc_azure_completion_retriever.py',\n",
    "    'model': AzureCompletionRetriever(),\n",
    "    'input_example': ['What is Databricks?'],\n",
    "}\n",
    "\n",
    "test_questions = [\n",
    "  'What is Databricks?',\n",
    "  'How does Databricks handle data storage?',\n",
    "  'What are the key features of Databricks?',\n",
    "  'How can I integrate Databricks with other tools?',\n",
    "  'What is the Databricks Lakehouse Platform?',\n",
    "  'How does Databricks support machine learning?',\n",
    "  'What are the benefits of using Databricks?',\n",
    "  'How can I secure my data in Databricks?',\n",
    "  'What is the pricing model for Databricks?',\n",
    "  'How can I get started with Databricks?',\n",
    "  'What is the role of Apache Spark in Databricks?'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1e5d3ea-61f4-43fe-87e9-277d164d1dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Test the approach and MLFlow Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9f8000b-9883-48c5-92db-7fe3bde6d86c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.models.signature import ModelSignature\n",
    "\n",
    "model = approach['model']\n",
    "input_example = approach['input_example']\n",
    "model.predict(None, input_example)\n",
    "\n",
    "signature = infer_signature(\n",
    "  model_input=input_example,\n",
    "  model_output=model.predict(None, input_example)\n",
    "  )\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18fbd0f2-19b2-4f8a-bb56-7a5f8064fac8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Time Raw Endpoint Calls via Class Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3146e662-e176-47cf-b7e3-dd3587330c57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import mlflow.pyfunc\n",
    "\n",
    "# Run test questions against the reloaded model and track the time for each response\n",
    "response_times = []\n",
    "for question in test_questions:\n",
    "    start_time = time.time()\n",
    "    model.predict(None, [question])\n",
    "    end_time = time.time()\n",
    "    response_times.append(end_time - start_time)\n",
    "\n",
    "print(f\"Response Time {np.mean(response_times):.2f} +- {np.std(response_times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97852070-97aa-4e57-89bd-ef043f3b24a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Can we predict on the whole list of questions? No. While we get a list in and out and the signature expects a list, the whole list goes in and we just take the last message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "136722c5-6331-4aaa-8a6e-cf8527d7b9b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.predict(None, test_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45f17b18-07f7-48d4-b7e5-4e412c18b68c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Log and Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "463af805-f4d3-4882-950c-438fdcd8e26f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    # Set the registry URI to Unity Catalog if needed\n",
    "    mlflow.set_registry_uri('databricks-uc')\n",
    "\n",
    "    # Log the model in MLflow with the signature  \n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        python_model=approach['file'],\n",
    "        model_config='config.yaml',\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"mlflow==2.18.0\",\n",
    "            \"openai==1.61.0\", \n",
    "            \"httpx==0.27.2\",\n",
    "            \"databricks-sdk[openai]\",\n",
    "            \"databricks-agents==0.12.0\"\n",
    "            ],\n",
    "        signature=signature\n",
    "        )\n",
    "\n",
    "    print(f\"Model logged with URI: {logged_agent_info.model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f348242-f332-4463-9998-99029aad1289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Register the Model in UC and Deploy. Here we use the standard mlflow.deployments model because we don't have a compatible agents framework signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4cb6dc4-5bc5-40f1-9e78-b2d5bfb811e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "import requests\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "model_name = f'shm.default.{approach[\"name\"]}'\n",
    "\n",
    "uc_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, \n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d11573f0-3f23-4158-89de-dbe4c964cacf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Reload the packaged model and profile local inference without serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0540f1fe-ee29-49ba-87ff-902c97eda005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "# Load the model\n",
    "reloaded_model = mlflow.pyfunc.load_model(\n",
    "    f\"models:/{uc_model_info.name}/{uc_model_info.version}\"\n",
    "    )\n",
    "\n",
    "reloaded_model.predict([question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5a34897-7e3a-47e5-a30c-846905d88d51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Run test questions against the reloaded model and track the time for each response\n",
    "response_times = []\n",
    "for question in test_questions:\n",
    "    start_time = time.time()\n",
    "    response = reloaded_model.predict([question])\n",
    "    end_time = time.time()\n",
    "    response_times.append(end_time - start_time)\n",
    "\n",
    "print(f\"Response Time {np.mean(response_times):.2f} +- {np.std(response_times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f311bd42-02d9-449d-b24f-cd6a8ad7c4b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Deploy the model after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64e318bc-e6a2-470f-90ee-080a9174bc9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "api_secret_key_name = config.get(\"api_secret_key\")\n",
    "search_secret_key_name = config.get(\"search_secret_key\")\n",
    "\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "serving_endpoint_name = f'shm-default-{approach[\"name\"]}'\n",
    "\n",
    "endpoint_config = {\n",
    "    \"served_entities\": [{\n",
    "        \"entity_name\": uc_model_info.name,\n",
    "        \"entity_version\": uc_model_info.version,\n",
    "        \"workload_size\": \"Small\",\n",
    "        \"scale_to_zero_enabled\": \"true\",\n",
    "        \"environment_vars\": {\n",
    "            \"API_SECRET_KEY\": f\"{{{{secrets/shm/{api_secret_key_name}}}}}\",\n",
    "            \"SEARCH_SECRET_KEY\": f\"{{{{secrets/shm/{search_secret_key_name}}}}}\"\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "\n",
    "try:\n",
    "    endpoint_info = client.get_endpoint(serving_endpoint_name)\n",
    "    print(f\"Endpoint {serving_endpoint_name} already exists, updating\")\n",
    "    client.update_endpoint(serving_endpoint_name, config=endpoint_config)\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    try:\n",
    "        client.delete_endpoint(serving_endpoint_name)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    endpoint = client.create_endpoint(\n",
    "            name=serving_endpoint_name,\n",
    "            config=endpoint_config\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1609869d-29a4-4887-935d-ae2c3811d65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Test the Serving Endpoint Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "862784c6-3bb8-414c-8ab3-55ac328be546",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import mlflow.pyfunc\n",
    "\n",
    "API_URL = f\"https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/{serving_endpoint_name}/invocations\"\n",
    "API_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "# Run test questions against the reloaded model and track the time for each response\n",
    "response_times = []\n",
    "for question in test_questions:\n",
    "    start_time = time.time()\n",
    "    data = {\"inputs\": [question]}\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "    response = requests.post(url=API_URL, json=data, headers=headers)\n",
    "    end_time = time.time()\n",
    "    response_times.append(end_time - start_time)\n",
    "\n",
    "print(f\"Response Time {np.mean(response_times):.2f} +- {np.std(response_times):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3530894374844369,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "driver_azure_completion_retriever",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
