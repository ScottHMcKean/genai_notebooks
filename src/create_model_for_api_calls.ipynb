{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0938110-1e81-4061-b62c-5c7db533e55d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai==1.6.1\n",
    "%pip install mlflow\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df6292a1-97ab-4bfc-9942-ae9382376ed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "api_base: str = \"https://dbmma.openai.azure.com/\"\n",
    "api_key: str = dbutils.secrets.get('shm','azure-gpt4-key')\n",
    "api_version: str = \"2024-02-15-preview\"\n",
    "deployment_id = \"gpt-4\"\n",
    "embedding_name = \"text-embedding-3-small\"\n",
    "embedding_api_version = \"2023-05-15\"\n",
    "azure_search_endpoint = \"https://fieldengeast-ai-search.search.windows.net\"\n",
    "azure_search_index = \"dbmma-manufacturing\"\n",
    "search_index_key = dbutils.secrets.get('shm','azure-ai-search')\n",
    "system_content = \"Respond in all caps\"\n",
    "question = 'How many chucks can a wood chuck chuk?'\n",
    "temperature = 0\n",
    "top_p = 0.95\n",
    "max_tokens = 800\n",
    "in_scope = True\n",
    "top_n_documents =  10\n",
    "query_type = \"vectorSemanticHybrid\"\n",
    "semantic_configuration = \"default\"\n",
    "role_information = \"Your name is AIDA\"\n",
    "strictness = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5654a728-ef4f-4f02-bb92-c0c717f213c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "class AIDAModel(mlflow.pyfunc.PythonModel):\n",
    "    def generate_response(self, question):\n",
    "        \"\"\"\n",
    "        Generate a response for a given question using predefined responses or Azure OpenAI.\n",
    "\n",
    "        Args:\n",
    "        - question (str): The question to generate a response for.\n",
    "        - config (ConfigParser): Configuration settings.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: A tuple containing the answer text and references.\n",
    "        \"\"\"\n",
    "\n",
    "        lower_question = question.lower().strip()\n",
    "       \n",
    "        system_content_ = '''\n",
    "        You are an AI assistant and expert in analyzing and synthesizing information from the documents provided to you.\\ \n",
    "        Do not respond to the questions out of your knowledge base.\\\n",
    "        If you are asked questions similar to the questions listed below, provide the answer given for each question:\\\n",
    "        ---- Question and Answers ----\n",
    "        User: \"what can you do?\"\n",
    "        AI: \"I am an AI assistant that helps people find information based on the {} dataset provided to me.\"\n",
    "\n",
    "        User: \"what can you help me with?\"\n",
    "        AI: \"I can read the {} dataset I have and give you the best answer to your question.\"\n",
    "\n",
    "        User: \"what is AIDA?\"\n",
    "        AI: \"AIDA stands for AI Digital Assistant.\"\n",
    "\n",
    "        User: \"what is the name of the dataset you are answering question based on?\n",
    "        AI: The dataset is called {}.\n",
    "        '''\n",
    "        data_name = \"BAPS, BAMS, and BAERD \"\n",
    "        system_content = system_content_.format(data_name, data_name, data_name)\n",
    "\n",
    "        message_text = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_content,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            client = AzureOpenAI(\n",
    "                api_key=api_key,\n",
    "                api_version=api_version,\n",
    "                azure_endpoint=api_base,\n",
    "            )\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_id,\n",
    "                messages=message_text,\n",
    "                temperature=float(temperature),\n",
    "                top_p=float(top_p),\n",
    "                max_tokens=int(max_tokens),\n",
    "                extra_body={\n",
    "                    \"data_sources\": [\n",
    "                        {\n",
    "                            \"type\": \"azure_search\",\n",
    "                            \"parameters\": {\n",
    "                                \"endpoint\": azure_search_endpoint,\n",
    "                                \"authentication\": {\n",
    "                                    \"type\": \"api_key\",\n",
    "                                    \"api_key\": search_index_key,\n",
    "                                },\n",
    "                                \"fieldsMapping\": {\n",
    "                                    \"content_fields\": [\"content\"],\n",
    "                                    \"title_field\": \"metadata_storage_name\",\n",
    "                                    \"url_field\": \"metadata_storage_path\",\n",
    "                                    \"filepath_field\": \"\",\n",
    "                                },\n",
    "                                \"index_name\": azure_search_index,\n",
    "                                \"in_scope\": in_scope,\n",
    "                                \"top_n_documents\": int(\n",
    "                                top_n_documents\n",
    "                                ),\n",
    "                                \"query_type\": query_type,\n",
    "                                \"semantic_configuration\": semantic_configuration\n",
    "                                or \"\",\n",
    "                                \"role_information\": role_information,\n",
    "                                \"embedding_dependency\": {\n",
    "                                    \"type\": \"deployment_name\",\n",
    "                                    \"deployment_name\": embedding_name,\n",
    "                                },\n",
    "                                \"strictness\": int(strictness),\n",
    "                            },\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            )\n",
    "\n",
    "            if response and response.choices:\n",
    "                combined_response = response.choices[\n",
    "                    0].message.content\n",
    "\n",
    "                return combined_response\n",
    "            else:\n",
    "                return [\"No response generated.\"]\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred while generating response: \")\n",
    "            return [\"Error processing your request.\"]\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        from openai import AzureOpenAI\n",
    "        pass\n",
    "\n",
    "    def predict(self, context, model_input: str):\n",
    "        return self.generate_response(str(model_input[\"question\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcfffb4f-bfef-4db2-8b18-e927bf2e034f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aida = AIDAModel()\n",
    "aida.generate_response('what is databricks SQL?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83669e1e-f814-41cf-b6e8-963902817a87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "model_path = \"aida_model\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "# Save the model\n",
    "mlflow.pyfunc.save_model(\n",
    "    path=\"aida_model\",\n",
    "    python_model=AIDAModel(),\n",
    "    extra_pip_requirements=[\"openai==1.6.1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cccb526-f445-4de6-8868-5ef6562394c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(\"aida_model\")\n",
    "\n",
    "# Example input\n",
    "model_input = [{\"question\":\"Tell me about the docs that you can retrieve\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8039df9-3664-4feb-b2f3-f9d3f3ae1950",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Log the model\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.pyfunc.log_model(\n",
    "      \"aida_model\",\n",
    "      python_model=AIDAModel(),\n",
    "      extra_pip_requirements=[\"openai==1.6.1\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58b4b62f-a7d4-4229-a900-c69dbcc5a425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_uri = f\"runs:/{run_id}/aida_model\"\n",
    "model_name = \"aida_model\"\n",
    "mlflow.register_model(model_uri, model_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "create_model_for_api_calls",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
