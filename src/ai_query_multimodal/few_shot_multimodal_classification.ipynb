{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eba19990-2ae8-4a7c-8e64-fc6ce7a20e80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Few Shot Multimodal Classification\n",
    "\n",
    "This notebook provides a quick example of doing few shot learning for multimodal classifcation of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c7345c8-94b7-492b-b2c6-1f4951290a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install httpx openai\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0586b03-b76f-4e6e-81e0-496fba2c4864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "There is a byte limit for images in requests, so we whip up a quick resize function and shrink our images. Aspect ratio doesn't matter much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2e52dac-0507-4ce1-8f73-a19f0b49dd75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import httpx\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def fetch_and_resize_image(url, size=(400, 400)):\n",
    "    response = httpx.get(url)\n",
    "    image = Image.open(io.BytesIO(response.content))\n",
    "    image.thumbnail(size)\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.standard_b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "media_type = \"image/jpeg\"\n",
    "\n",
    "combo_data = fetch_and_resize_image(\"https://upload.wikimedia.org/wikipedia/commons/b/b7/Kluc_ockoplochy.jpg\")\n",
    "adjustable_data = fetch_and_resize_image(\"https://upload.wikimedia.org/wikipedia/commons/4/44/Adjustablewrenches.jpg\")\n",
    "pipe_wrench_data = fetch_and_resize_image(\"https://upload.wikimedia.org/wikipedia/commons/b/b1/Ridgid_10%22_pipe_wrench.jpg\")\n",
    "test_adjustable_data = fetch_and_resize_image(\"https://upload.wikimedia.org/wikipedia/commons/4/43/AdjustableWrenchWhiteBackground.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7610ce41-1b6a-41f5-a0ad-bfa6adf1f9fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can pass multiple images via a list in the 'content' field. This is pretty useful for assembling multiple images/byte streams. And bam, we have a few-shot multimodal image classification! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14e06908-d7b8-437d-b021-e9c1d647877e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=\"https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a mechanic tool classification expert. Use \"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Image 1 - a combo wrench\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{media_type};base64,{combo_data}\"}},\n",
    "        {\"type\": \"text\", \"text\": \"Image 2 - an adjustable wrench\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{media_type};base64,{adjustable_data}\"}},\n",
    "        {\"type\": \"text\", \"text\": \"Image 3 - a pipe wrench\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{media_type};base64,{pipe_wrench_data}\"}},\n",
    "        {\"type\": \"text\", \"text\": \"What is the name of the tool in the following image and does it match any of the examples your were provided?\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{media_type};base64,{test_adjustable_data}\"}}\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  model=\"databricks-claude-3-7-sonnet\",\n",
    "  max_tokens=1024\n",
    ")\n",
    "\n",
    "parsed_text = chat_completion.choices[0].message.content\n",
    "print(parsed_text)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "few_shot_multimodal_classification",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
