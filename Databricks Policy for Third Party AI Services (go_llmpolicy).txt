Databricks Policy for use of Third-Party AI Services 
________________


self-link : go/llmpolicy 
Overview 
Databricks recognizes that generative AI is a priority for the enterprise, and encourages employees to use generative AI services to (a) streamline their work, (b) power internal services, and (c) build products and features for Databricks. To guide usage of these services, Databricks has prepared the guardrails below.[1] In this policy employees will find set-up instructions, data usage information, and AI governance processes (e.g., legal, security, and engineering approval requirements). Employee use of these tools and any resulting outputs must be consistent with this policy and Databricks’ core principles. You can find guardrails for using AI Tools here: Enterprise AI Tools Policy - Published Final Version.


This policy is updated annually.[2] 
Summary 
Employees may use the following services pursuant to the directions contained in this document. This list will be updated as we incorporate more tools and systems:
* ChatGPT
* Claude.ai Chat & Claude Code
* Enterprise Copilot
* Enterprise OpenAI & Managed Azure OpenAI APIs
* Enterprise Claude Opus & Sonnet APIs
* Grammarly
* Gemini in Google Workspaces
* Goose
* NotebookLM
* Perplexity AI (Perplexity Pro)
* ZoomAI and other approved transcription services. 


See below for setup instructions and permitted data for each specific service. All services should be set up using your employee@databricks.com email address, and minimize the exposure of confidential information, customer information, and personally identifiable information. Generally, you may only submit Databricks data such as docs, code snippets, and internal slack, for summarization, transcription, and generation. This excludes highly confidential data like financials, secret credentials, and personally identifiable information (employee, contractor, or Databricks user names) etc. You may also reference the Data Usage Permissions Summary Chart in Appendix A, which lists permitted data by input data type for more detailed information.


Note - You may not use any non-GA features of approved services (e.g., beta, experimental, preview, or equivalent features) or any unapproved APIs as they may provide access to such non-GA features (e.g., non-enterprise APIs).  If your use case diverges from what is permitted below, you must file go/edc/new or go/lpp & go/sdr to make sure that you have legal and security approval prior to production. If you aren’t sure your use case fits an approved use case, please ask in #ai_legal (Slack). If you would like to use a new third-party service that is not listed here, you must submit a ticket through go/procurement to vet and acquire that service. If you would like to build a Databricks-hosted generative AI model for use within the Databricks customer-facing platform, you must follow standard procedures and submit a JIRA ticket for engineering design review that will trigger both legal and security reviews (go/edc/new). If you would like to build internally-consumed services powered by AI models, please file at go/lpp and go/sdr tickets for legal and security review.
ChatGPT, Claude.ai Chat, & Claude Code
How to set up services:  Sign up for these services using your databricks.com account (use Google SSO for authentication instead of a password). Opt out of the “improve model for everyone” to ensure that data is not used for model training for ChatGPT. Claude has a default off on using chats to train, but your user feedback (thumbs up and thumbs down) can be used for training. 
Data Allowed:
* Non-Confidential General Info (e.g., what you would do on Google Search)
* Databricks Confidential & Proprietary Information:  Yes, except no highly confidential information - e.g., financials, privileged projects, secret credentials, etc.
   * Code, PRDs, Design Docs, Documentation (e.g., eng SOPs) may be used.
   * Slack content may be used assuming no highly confidential information or data categories in the “Data Not Allowed” section. 
   * Employees must use their discretion to ensure they are not using highly sensitive Databricks information, e.g. financials forecasting, private channel data, secrets/tokens/keys, information marked as “privileged and confidential,” or “ACP”. 
Data Not Allowed:
* Account Data
* Customer Data
* Personal Data of Prospects for Marketing
* Personal Data of Databricks Users
* Databricks Employee Data
* Customer Support Data
* Regional logfood data (e.g Service & Spark Logs)
* Central logfood 
   * Product usage information and usage logs
   * Structured logs like RPC log, Activity log
   * HTTP Access logs
Enterprise Copilot 
How to set up services:  Do not use any non-enterprise Copilot. You may opt in to the Databricks Enterprise Copilot at go/copilot. This will enable you to work on Databricks managed code repositories in the Databricks organization and OSS.  Do not open logs with customer data in a copilot enabled editor.  
Data Allowed in Enterprise Copilot:
* Non-Confidential General Info (e.g., what you would do on Google Search)
* Databricks Confidential & Proprietary Information:  Yes, except no highly confidential information - e.g., financials, privileged projects, secret credentials, etc.
   * Code, PRDs, Design Docs, Documentation (e.g., eng SOPs) may be used.
   * Slack content may be used assuming no highly confidential information or data categories in the “Data Not Allowed” section. 
   * Employees must use their discretion to ensure they are not using highly sensitive Databricks information, e.g. financials forecasting, private channel data, secrets/tokens/keys, information marked as “privileged and confidential,” or “ACP”.”
* Customer Platform Assets (defined in go/datapolicy) and Metadata about Customer Content - Permitted for AWS/GCP in limited circumstances:
   * Databricks employees must disclose the data flow to the customers (transparency) and record consent from customers (specifically, someone at an admin level or higher) to use data in all tools. 
   * With such consent Customer Platform Assets and Metadata about Customer Content may be used. 
   * For Copilot, services may only be provided for single tenant environments.
   * Core Customer Data (e.g., their data from their S3 buckets/ table content) may NOT be used in any GenAI services.
* Central logfood: Two categories permitted:
   * Product usage information and usage logs.
   * Structured logs like RPC log, Activity log.
Data Not Allowed in Enterprise Copilot:
* Account Data
* Personal Data of Prospects for Marketing
* Personal Data of Databricks Users
* Core Customer Data (e.g., their data from their S3 buckets/ table content) 
* Databricks Employee Data
* Customer Support Data
* Regional logfood data (e.g Service & Spark Logs)
* Central logfood - HTTP Access logs
Enterprise OpenAI, Managed Azure OpenAI, Claude Opus, Sonnet, & Goose
How to set up services:  Instructions on how to set up, use, and detail about use cases for these APIs and agents are available at go/llm-proxy and go/llm/agent respectively.  These APIs are accessed via our control plane.  Prior to moving any use case to production you’ll need to follow the standard security review process at go/SDR and legal product and privacy review via go/lpp. 
Data Allowed:
* Non-Confidential General Info (e.g., what you would do on Google Search)
* Account Data:  This may only be used in Managed Azure OpenAI API, except if you are using data for non-Azure accounts, you may use the other APIs. 
* Customer Platform Assets (defined in go/datapolicy) and Metadata about Customer Content - Permitted in limited circumstances:
   * Databricks employees must disclose the data flow to the customers (transparency) and record consent from customers (specifically, someone at an admin level or higher) to use data in all tools. 
   * With such consent Customer Platform Assets (defined in go/datapolicy) and Metadata about Customer Content may be used. 
   * Core Customer Data (e.g., their data from their S3 buckets/ table content) may NOT be used in any GenAI services.
   * Azure data may only be used with Managed Azure OpenAI API, NOT OpenAI or other APIs, and employees must adhere to Azure data residency requirements.
* Databricks Confidential & Proprietary Information:  Yes, except no highly confidential information - e.g., financials, privileged projects, secret credentials, etc.
   * Code, PRDs, Design Docs, Documentation (e.g., eng SOPs) may be used.
   * Slack content may be used assuming no highly confidential information or data categories in the “Data Not Allowed” section. 
   * Employees must use their discretion to ensure they are not using highly sensitive Databricks information, e.g. financials forecasting, private channel data, secrets/tokens/keys, information marked as “privileged and confidential,” or “ACP”.
* Personal Data of Prospects for Marketing: Permitted with the following requirements: 
   * Employees must file a Privacy Impact Assessment per use case 
   * Employees must demonstrate to Legal that the proposed use case is consistent with the data subject’s expectations of how the data would be used or aligned with the purpose for which the data was collected 
   * Employees must clearly set forth the purpose of the use case and provide access and use limitations
* Databricks Employee Data: Yes, subject to the following requirements: 
   * Employees must file a Privacy Impact Assessment per use case.
   * Employees must demonstrate to Legal that the proposed use case is consistent with the data subject’s/ originating employee’s expectations of how the data would be used or aligned with the purpose for which the data was collected.
   * Employees must clearly set forth the purpose of the use case and provide access and use limitations. 
   * This data cannot be used in a way that is considered “automated decision making.”
   * The Employee Handbook must be updated to reflect the data use. 
* Customer Support Data:  This may only be used in Managed Azure OpenAI API with the following conditions:
* Employees remove personally identifiable information/ personal data where possible.
* When/If approved for use in production:
   * Employees must ensure that customers consent to data being shared via the API.
   * Customers must be aware/ the use of Azure OpenAI must be transparent.
* Central Logfood
   * Central logfood - Product usage information (usage_logs), Structured logs like RPC log, Activity log
      * Azure OpenAI:  Yes
      * Claude Opus, Sonnet, OpenAI:  Yes on AWS/GCP, No on Azure
   * Central logfood - HTTP Access logs
      * Azure OpenAI:  Yes, either with removal of personal data (userIDs) or 
         * Privacy Impact Assessment per use case must be filed; and
         * Explanation of purpose of use that aligns with how/why we collect the data and expect it to be used.
      * Claude Opus, Sonnet, OpenAI:  No
Data Not Allowed:
* Core Customer Data (e.g., their data from their S3 buckets/ table content) 
* Personal Data of Databricks Users
* Regional logfood data (e.g Service & Spark Logs)
Grammarly
How to set up services:  This must be provisioned to you by IT and cannot be your personal account. 
Data Allowed in Grammarly:
* Non-Confidential General Info (e.g., what you would do on Google Search)
* Databricks Confidential & Proprietary Information:  Yes, except no highly confidential information - e.g., financials, privileged projects, secret credentials, etc.
   * PRDs, Design Docs, Documentation (e.g., eng SOPs) may be used.
   * Slack content may be used assuming no highly confidential information or data categories in the “Data Not Allowed” section. 
   * Employees must use their discretion to ensure they are not using highly sensitive Databricks information, e.g. financials forecasting, private channel data, secrets/tokens/keys, information marked as “privileged and confidential,” or “ACP”.
Data Not Allowed in Grammarly
* Account Data
* Customer Data
* Personal Data of Prospects for Marketing
* Personal Data of Databricks Users 
* Databricks Employee Data
* Customer Support Data
* Regional logfood data (e.g Service & Spark Logs)
* Central logfood 
   * Product usage information and usage logs
   * Structured logs like RPC log, Activity log
   * HTTP Access logs
Perplexity (Perplexity Pro)
How to set up services:  Employees have free access to this until January 28, 2025. Employees may use this for general research (like Google Search). 
Data Allowed in Perplexity:
* Only non-confidential information. 
Gemini & NotebookLM
This tool is part of your Google Workspace. You may use this tool in the same manner that you use other Google tools in your Google Workspace (e.g. Google Docs, Google Slides).
ZoomAI and other approved transcription services
Employees already have access to certain tools (e.g., ZoomAI). If you are using these you must include consent acknowledgement, honor requests to turn off recordings, and must be able to correct any inaccuracies in any transcriptions promptly. These recordings may not be distributed outside Databricks without manager approval.
How Can I Use Outputs from these Gen AI Services?
ChatGPT, Claude.ai Chat, Perplexity, & Grammarly: Use your discretion as an employee of Databricks in determining whether you should use the output in your work. Remember to fact check and review output for consistency with your intended approach/goal. Make sure to use these tools within the guardrails set forth (e.g., create a PRD using ChatGPT but do not feed it highly sensitive or confidential information).


Other Ways to Use Outputs:
* Code Generation: If you’re using a tool to generate code that you’d like to incorporate into your work or product, you must go through the standard SDLC process (including code review and sign off) prior to doing so. This includes code generated from OpenAI, CoPilot, and any other tools that enable you to generate code.
* Perf Review: If you’re using ChatGPT or Claude.ai chat, refer to the self-eval guidelines available at go/perf.
GenAI and Security
If part of the input (including anything used in training) is untrusted, the output should be considered untrusted. For additional information you can read[Draft] LLM Security Guidelines.  If you want to develop an LLM or use an LLM or AI-based service or tool that isn’t already approved by Legal PnP and the Security team for your particular use case  please file a go/lpp and a go/sdr ticket to get approval before trying to go to prod. Additional steps may include filling out a Privacy Impact Assessment (PIA) and  working through an AI Impact Assessment with your assigned Legal Product lawyer to ensure that we’re meeting customer commitments, internal policies, and regulatory requirements. 
What do I need to do before releasing my feature to production?
You need to have your feature reviewed by security, legal and create the appropriate customer facing resources to disclose what data we share with the 3rd party and when we share it. 


Here’s an example from the Notebook Assistant feature.
1. SDR (security): SDR-1135 
2. LPP (legal): LPP-846 
3. Customer FAQ that covers data usage:  [Internal] LakeSense FAQ (go/lakesense-faq)






________________


Appendix A: Data Usage Permissions Summary Chart
Note: This chart does not include Zoom or other transcription services, or Gemini & NotebookLM. 


Input Data Type
	Examples
	Enterprise Copilot
	ChatGPT/
ChatGPT+


Claude.ai Chat 


Claude Code


Grammarly


	Managed Azure OpenAI API 
	Enterprise OpenAI API 
Claude Opus, Sonnet, Goose
	Perplexity AI
	Non-Confidential General Info (e.g., what you would do on Google Search)
	

	Yes
	Yes
	Yes
	Yes
	Yes
	Account Data
	Account owner email address


Billing contact owner


Primary customer-contact for product 


Customer meeting notes
	No
	No
	Yes
	Yes, but for non-Azure accounts only.
* Databricks isn’t the “controller” of basic Azure Account Data, so we can’t use third parties without making them “subprocessors” for Azure Databricks
	No
	Customer data 
	Customer Platform Assets (e.g, notebook, code, dashboards, or anything else  customer creates for using Databricks) 


e.g., job names; customer code
	Yes for AWS/GCP, with disclosure & consent


1. Does customer know
2. Did customer (admin level of higher) consent
3. Do we have record of the consent


For providing services for a single tenant.


This data is unlikely to intersect with copilot which is intended to operate on Databricks Code.
	No
	Yes, for all clouds with disclosure & consent 


Same 3 flags as CoPilot


**Also need to keep Azure Databricks customer consistent with ADB Data Residency commitments


	Yes, for AWS/GCP with disclosure and consent  


Same 3 flags as CoPilot


No for Azure MSFT, requires approval from MSFT for Azure Databricks data.




	No
	

	Metadata about customer content (e.g., column names)
	See above
	No
	See above
	See above
	No
	

	Core Customer Data (e.g., their data from their S3 buckets/ table content)
	No
	No
	No
	No
	No
	Databricks Confidential & Proprietary Information
	Code, PRDs, Design Docs, and other Internal Databricks documentation, Internal Databricks Slack (Databricks Confidential) 


No highly confidential information - e.g., financials, privileged projects, secret credentials, etc.
	Yes
	Yes
	Yes
	Yes
	No
	Personal Data of prospects for marketing


(Marketing/Sales/Leads)
	CRM data
Full names
Email address
Mailing address 


	No
	No
	Only if you meet the requirements below


1) a Privacy Impact Assessment per use case must be filed
2) a confirmation that however we collected this data allows us to use it for model training or development (or as input)
3) What we'd be using the output for exactly (e.g., will this result in automated decision-making)
	Only if you meet the requirements below


1.  a Privacy Impact Assessment per use case
2.  a confirmation that however we collected this data allows us to use it for model training or development (or as input)
3. What we'd be using the output for exactly (e.g., will this result in automated decision-making)


	No
	Databricks Employee Data
	Employee information (position/salary/full name/address and other EE- related info)
	No
	No
	Only with the same restrictions as other Personal Data, plus the following requirements:




(1) output isn't used for automated-decision making about EEs
(2) The EE handbook is updated to reflect potential uses of personal data
(3) Work with employer/privacy for other related concerns
(4) Fill out a PIA and provide purpose of/ use of personal data
	Only with the same restrictions as other Personal Data, plus the following requirements:




(1) output isn't used for automated-decision making about EEs
(2) The EE handbook is updated to reflect potential uses of personal data
(3) Work with employer/privacy for other related concerns
(4) Fill out a PIA and provide purpose of/ use of personal data


	No
	Personal Data of Databricks Users


	Email address 


Full name


Device ID


Pseudo-UserID
	No
	No
	No
	No
	No
	Customer 
Support Data
	Salesforce support ticket content 


Information from JIRA support tickets


Slack support channels or information with customers.
	No
	No
	 Yes, if the following conditions are met: 


1. Customer knows we’re using Azure OpenAI backend and understands data transmission/use (either intuitive, configured by customer, or clearly stated)
2. Customer consents/opts in
3. We have some record of the opt in
4. If possible, remove PII.


	No
	No
	Regional logfood data (e.g Service & Spark Logs)
	

	No
	No
	No
	No
	No
	Central logfood - Product usage information
(usage_logs)
	Telemetry
	Yes
	No
	Yes
	Yes on AWS/GCP


No on Azure
	No
	Central logfood - Structured logs like RPC log, Activity log
	

	Yes
	No
	Yes
	Yes on AWS/GCP


No on Azure
	No
	Central logfood - HTTP Access logs
	

	No
	No
	Yes, either with removal of personal data (userIDs) or 


1) a Privacy Impact Assessment per use case must be filed


2) Explanation of purpose of use that aligns with how/why we collect the data and expect it to be used.
 
	No
	No
	



Appendix B: Versioning
Review Status Version 7 (7/2025)
Changelog: Updated to add Claude Code


Review Status Version 6 (4/2025)


Approver
	Approval Status
	Approval Date
	Comments
	Lead Counsel Product/ Suchismita Pahi
	Approved
	

	Updated services & overview (see Changelog below)
	Changelog: 
* Updated to add note regarding non-GA features and Goose.
Review Status Version 5  (2/2025)


Approver
	Approval Status
	Approval Date
	Comments
	Lead Counsel Product/ Suchismita Pahi
	Approved
	Feb 21, 2025
	Updated services & overview (see Changelog below)
	Changelog: 
* Updated to add services, specifically Gemini enabled through Databricks Google Workspaces. 
* Updated to add Enterprise AI Tools Policy - Published Final Version
Review Status Version 4  (11/2024)


Approver
	Approval Status
	Approval Date
	Comments
	Engineering Ted Tomlinson
	Approved
	Nov 21, 2024
	

	Lead Counsel Product/ Suchismita Pahi
	Approved
	Nov 21, 2024
	Updated services (see Changelog below)
	Changelog: 
* The November version was updated to add guidance for NotebookLM, Enterprise Anthropic API access, and Claude.ai (chat) and to further clarify Slack content use.
* Reviewers were limited to a subset of the key stakeholders as this is not a large substantive update to the policy. 
Review Status Version 3 (10/2024-10/2025)


Approver
	Approval Status
	Approval Date
	Comments
	Engineering Ted Tomlinson
	Approved
	Sep 23, 2024
	Some comments about future services and clarifications on use cases. 
	Engineering Manager Vinod Marur
	Not started
	

	

	Legal Manager Neal Hannan
	Not started
	

	

	Lead Counsel Product/ Suchismita Pahi
	Approved
	Oct 1, 2024
	Reviewed with some minor language changes, and added a “pending” bullet for tools to include Anthropic.
	Security Mrityunjay Gautamor Thomas Garnier
	Under review
	

	LGTM from Thomas Garnier, waiting if Mrityunjay Gautam has feedback before approving.
	Security Manager Fermin Serna
	Not started
	

	

	Trust & Safety Mainak Sen
	Approved
	Sep 23, 2024
	Left some comments.
	Changelog: 
* The October 1 version is updated generally for readability
* This update included clarification of what the internal software development life cycle (SDLC) includes (removed manager approval)
* This update includes a review cadence and note that tools will be added continuously to the tools section
* Updated to include DATE for Perplexity access
Aug 4, 2024- Revised in structure to make it easier to read.
Review Status Version 2 (Current 3/2024-3/2025)
Primary Reviewer*
	LGTM blockers [?]
	Review
	Updated
	Neal Hannan(legal)
	LGTM
	* 	Feb. 22, 2023
	Vinod Marur(eng)
	LGTM
	* 	Feb 23, 2023
	Fermin Serna (SEC)
	LGTM
	* 	March 6, 2024
	

Review status - Version 1
Primary Reviewer*
	LGTM blockers [?]
	Review
	Updated
	Neal Hannan(legal)
	LGTM in current stat (June 8, 2023)
	* 	Jun 8, 2023
	Vinod Marur(eng)
	LGTM with same caveats as from Fermin below.  Would like to timebox approval and force a review in six months
	* 	June 16, 2023
	Fermin Serna (SEC)
	LGTM is conditioned to restrict employee data and highly confidential Databricks information (acquisitions, financial data, privileged projects, …)
	* 	May 31, 2023
	Other Reviewers (team)
	

	Mainak Sen(trust and safety eng)
	Lgtm, there are some process safeguards which are easy for folks to forget. We should look at periodic reminder
	* 	May 12, 2023
	Suchismita Pahi(legal)
	Conditioned on adding in that Security doc info and accepting suggested changes
	* 	May 22, 2023
	Micheal Benedict(dev platform)
	lgtm
Note: sourcegraph launched Cody recently, we don’t use it internally yet but would have to add it to this list in the future
	* 	May 24, 2023
	Ted Tomlinson(eng)
	

	* 	May 12, 2023
	Mrityunjay Gautam(sec)
	

	* 	

	



ATTORNEY-CLIENT PRIVILEGED  - DO NOT SHARE EXTERNALLY                        
________________
[1] Stakeholders: Engineering (Ted TomlinsonVinod Marur), Trust & Safety (Mainak Sen), Security (Kostya KortchinskyThomas GarnierMrityunjay GautamFermin Serna), Legal Product & Privacy (Neal HannanSuchismita Pahi), Legal (Tram Phi). 
[2] Last Updated: Apr 7, 2025  (see Appendix B for Changelog)