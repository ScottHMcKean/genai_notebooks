{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95e52634-ff7c-44b8-b471-0b01c8028c4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Inference Tables to MLflow\n",
    "This notebook goes over pulling inference tables into an MLflow experiment for further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a6ff590-95cf-43a8-ada9-2791e25ce0c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow --upgrade\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd5810bf-8818-4eb8-96ba-c24ea4b9521b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "import json\n",
    "from mlflow.entities import SpanType\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional\n",
    "from pandas._libs.tslibs.timestamps import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff422a85-9c19-42dd-afaf-853b65485079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"/Workspace/Users/scott.mckean@databricks.com/experiments/inf_to_mlflow\"\n",
    "INFERENCE_TABLE = \"shm.3w.well_agent_payload\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8154eea3-9659-4d0e-8224-1927d04cdd93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "exp_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc5bd049-6de7-4903-84fc-c6f46a22f556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extract Inference Table\n",
    "We use spark to pull the inference table. You can see that MLflow can display the trace directly when using display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fba2763b-23be-470f-b4f0-a20d6b3c6dda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(INFERENCE_TABLE)\n",
    "df_pd = df.toPandas()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "432644d8-86b2-44ac-87b7-8087c889b7b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transfer to MLflow\n",
    "We wrap a low-level API to log the trace into MLflow with as little modifications as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1347f1a9-bad0-4680-91b1-56d27df13c66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_inference_row_trace(row: pd.Series) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Create a single MLflow trace from a row of an inference table\n",
    "    \"\"\"\n",
    "    request_data = json.loads(row['request'])\n",
    "    response_data = json.loads(row['response'])\n",
    "    start_time = int(pd.to_datetime(row['request_time']).timestamp() * 1e9)\n",
    "    end_time = int(start_time + row['execution_duration_ms'] * 1e6)\n",
    "    total_tokens = json.loads(response_data['databricks_output']['trace']['info']['trace_metadata']['mlflow.trace.tokenUsage'])['total_tokens']\n",
    "\n",
    "    span = client.start_trace(\n",
    "      row['databricks_request_id'], \n",
    "      span_type='CHAIN',\n",
    "      inputs=request_data,\n",
    "      attributes={\n",
    "          \"execution_duration_ms\": row['execution_duration_ms'],\n",
    "          \"status_code\": row['status_code'],\n",
    "          \"request_time\": row['request_time'],\n",
    "          \"sampling_fraction\": row['sampling_fraction'],\n",
    "          \"llm.token_usage.input_tokens\": 5,\n",
    "          \"llm.token_usage.output_tokens\": 10,\n",
    "          \"llm.token_usage.total_tokens\": 15\n",
    "      },\n",
    "      tags={\n",
    "          \"source\": \"inference_table\",\n",
    "          \"databricks_request_id\": row['databricks_request_id'],\n",
    "          \"client_request_id\": row['client_request_id'],\n",
    "          \"served_entity_id\": row['served_entity_id'],\n",
    "          \"requester\": row['requester'],\n",
    "      },\n",
    "      start_time_ns=start_time\n",
    "      )\n",
    "\n",
    "    client.end_trace(\n",
    "      trace_id=span.trace_id,\n",
    "      outputs=response_data,\n",
    "      end_time_ns=end_time,\n",
    "\n",
    "      )\n",
    "    \n",
    "    return span.trace_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e05e5c9c-f03b-4b98-a411-ef4aaccaaea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(INFERENCE_TABLE).toPandas()\n",
    "for idx, row in df_pd.iloc.iterrows():\n",
    "    trace_id = log_inference_row_trace(row)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "inference_table_to_mlflow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
