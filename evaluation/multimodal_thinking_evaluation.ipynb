{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "690a85ea-f716-4cc9-9b84-6b808c657543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Thinking Model Logging Example\n",
    "This notebook provides a quick summary of what you would get from logging a multimodal model call from a model like Claude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53f089cb-dbdb-4c74-a401-df60cf8c5db3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai mlflow\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82c1a291-9c06-4342-83d4-83a1fd61ed72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inference without thinking budget\n",
    "Here is inference without a thinking budget, where we simply get a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f115d2c-80eb-4187-b7a6-9c91bcb80981",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "import mlflow\n",
    "import io\n",
    "\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "# Path to image file in Databricks volume\n",
    "image_path = \"./image.png\"\n",
    "\n",
    "# Read and encode the image\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=\"https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"\"\"\n",
    "            Question: What is the missing color of the part denoted with a question mark?\n",
    "          \n",
    "            Options: (A) Purple (B) Green (C) Blue (D) Yellow\n",
    "            \n",
    "            Answer: Let's describe the image first and think step by step.\n",
    "            \"\"\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}}\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  model=\"databricks-claude-3-7-sonnet\",\n",
    "  max_tokens=512\n",
    ")\n",
    "\n",
    "parsed_text = chat_completion.choices[0].message.content\n",
    "print(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09d667b5-b17d-491b-b8f1-bf38114b88f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inference with thinking enabled\n",
    "The response varies a bit when you enable thinking mode. Note the difference in the logging - we get the entire message stream back because the output format is slightly different, but once again it is only logged in a single step because MLflow can't introspect within the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9578d5f-0f2a-4d9e-87fc-309cc01b544c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.openai.autolog()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=\"https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"\"\"\n",
    "            Question: What is the missing color of the part denoted with a question mark?\n",
    "          \n",
    "            Options: (A) Purple (B) Green (C) Blue (D) Yellow\n",
    "            \n",
    "            Answer: Let's describe the image first and think step by step.\n",
    "            \"\"\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}}\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  model=\"databricks-claude-3-7-sonnet\",\n",
    "  max_tokens=1500,\n",
    "  extra_body={\n",
    "      \"thinking\": {\n",
    "          \"type\": \"enabled\",\n",
    "          \"budget_tokens\": 1024,\n",
    "      }\n",
    "  },\n",
    ")\n",
    "\n",
    "parsed_text = chat_completion.choices[0].message.content\n",
    "print(parsed_text)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "multimodal_thinking_evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
